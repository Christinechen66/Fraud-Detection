{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of outlier detection fraud data python3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christinechen66/Fraud_Detection/blob/main/Copy_of_outlier_detection_fraud_data_python3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e3W6bZoA8E3"
      },
      "source": [
        "## Please ***DO NOT*** edit/run this notebook directly, otherwise others will have trouble rerunning the cells!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "please click File -> save a copy in your own drive or download instead, then play with your copy! Thanks!\n",
        "\n",
        "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
        "where we have 492 frauds out of 284,807 transactions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkPeS6NgA7Nu"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot7ZHfdC9tEa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns, numpy as np\n",
        "\n",
        "from numpy import genfromtxt\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import f1_score\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoyZxvFs0NQt"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m3Ou494BtEW",
        "outputId": "fc55de37-e569-4d5b-feb9-1c792e86cf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# method 1: save the data in https://drive.google.com/drive/folders/1h7dB3SLd6HYJAisALnMax28r1idDS-N6 to your own google drive: \n",
        "# create a folder: fraudData in https://drive.google.com/drive/u/0/my-drive (the home folder of gDrive is: My Drive), put the file: creditcard.csv in folder fraudData\n",
        "# then follow Garima Jain in https://stackoverflow.com/questions/48340341/read-csv-to-dataframe-in-google-colab\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLDTexCfACAN",
        "outputId": "f949b95f-05b9-4b65-af66-d4236c17c378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/creditcard.csv\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/Colab Notebooks/creditcard.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmuK3QLcFieZ",
        "outputId": "8971c801-c53c-4b3d-d7ae-f0c091ccba02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAsrQUiLBFd4",
        "outputId": "1c965245-5fa6-456c-fff7-472a22d54eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "creditcardDF = pd.read_csv('drive/My Drive/fraudData/creditcard.csv') #much faster once saved in drive\n",
        "creditcardDF.head()#all numerical"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c538b342a4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreditcardDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/fraudData/creditcard.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#much faster once saved in drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcreditcardDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#all numerical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/fraudData/creditcard.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARb8-Y2e-Nlk"
      },
      "source": [
        "#method 2a, very slow, not suggested\n",
        "#download the creditcard.csv to your local machine, then upload it:\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# It will prompt you to select a file. (may need to rerun this cell to enable this). Click on “Choose Files” then select and upload the file. Wait for the file to be 100% uploaded. \n",
        "# You should see the name of the file once Colab has uploaded it. this may take up to 15 mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrKCMkg4gh_K"
      },
      "source": [
        "##method 2b, Finally, type in the following code to import it into a dataframe (make sure the filename matches the name of the uploaded file).\n",
        "\n",
        "\n",
        "creditcardDF = pd.read_csv(io.BytesIO(uploaded['creditcard.csv']))\n",
        "\n",
        "creditcardDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmbDYSzDHd1a"
      },
      "source": [
        "#Distribution of the label column\n",
        "creditcardDF['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRXR-vc1JJ3m"
      },
      "source": [
        "492 / (284315  + 492) #<0.2 percent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZLQtN8uIQp8"
      },
      "source": [
        "creditcardDF.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2hF4Q5st6Ji"
      },
      "source": [
        "creditcardDF.isna().sum()#null checking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_wWarLPuQ5v"
      },
      "source": [
        "\n",
        "\n",
        "sns.distplot(creditcardDF['Time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s5s4tUSuQm9"
      },
      "source": [
        "\n",
        "sns.distplot(creditcardDF['Amount'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1lrJCCou_Bo"
      },
      "source": [
        "creditcardDF['Amount'] = np.log(creditcardDF['Amount'] + 1)\n",
        "\n",
        "creditcardDF['Time'] = np.log(creditcardDF['Time'] + 1)\n",
        "\n",
        "normal = creditcardDF[creditcardDF['Class'] == 0]\n",
        "anomaly = creditcardDF[creditcardDF['Class'] == 1]\n",
        "\n",
        "train, test = train_test_split(normal, test_size=0.2, random_state=0)\n",
        "normal_valid, normal_test = train_test_split(test, test_size=0.5, random_state=0)#all normal/good\n",
        "anomaly_valid, anomaly_test = train_test_split(anomaly, test_size=0.5, random_state=0)#all anomaly/bad\n",
        "\n",
        "validation = pd.concat([normal_valid, anomaly_valid])#include both good and bad\n",
        "test = pd.concat([normal_test, anomaly_test])#include both good and bad\n",
        "\n",
        "\n",
        "print(validation.shape)\n",
        "print(test.shape)\n",
        "\n",
        "train = train.drop(columns = ['Class']).reset_index(drop= True)#no need of label in train data, drop it\n",
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb6GZTYC9O97"
      },
      "source": [
        "featureNames = list(train.columns.values)#feature names only, no label\n",
        "valFeatures = validation[featureNames].reset_index(drop= True)#feature df only, no label\n",
        "testFeatures = test[featureNames].reset_index(drop= True)#feature df only, no label\n",
        "\n",
        "valLabel = validation['Class']#label df only\n",
        "testLabel = test['Class']#label df only\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW20aYtk3lo1"
      },
      "source": [
        "valFeatures.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFURxHtfu-cv"
      },
      "source": [
        "validation['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01oHXvrc4xEz"
      },
      "source": [
        "test['Class'].value_counts()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC4U5x8f_fIu"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"train data of V1 and V2\")#may contain outliers\n",
        "plt.xlabel(\"V1\")\n",
        "plt.ylabel(\"V2\")\n",
        "plt.plot(train.iloc[:, 1],train.iloc[:,2],\"bx\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClT7DCgz_hZ5"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"validation data of V1 and V2\")\n",
        "plt.xlabel(\"V1\")\n",
        "plt.ylabel(\"V2\")\n",
        "plt.plot(validation.iloc[:, 1],validation.iloc[:,2],\"bx\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS8r6bm1_lTB"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"test data of V1 and V2\")\n",
        "plt.xlabel(\"V1\")\n",
        "plt.ylabel(\"V2\")\n",
        "plt.plot(test.iloc[:, 1],test.iloc[:,2],\"bx\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX9Auo2Y_vrG"
      },
      "source": [
        "np.arange(1, 20, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7IkBlGp_xum"
      },
      "source": [
        "# def read_dataset(filePath, delimiter=','):\n",
        "#     return genfromtxt(filePath, delimiter=delimiter)\n",
        "\n",
        "#find parameter for each col/feature in df for the Gaussian distribution\n",
        "def estimateGaussian(dataset):\n",
        "    mu = np.mean(dataset, axis=0)\n",
        "    sigma = np.cov(dataset.T)\n",
        "    return mu, sigma\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86g-XAQb-Upk"
      },
      "source": [
        "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html\n",
        "#Return evenly spaced numbers over a specified interval.\n",
        "np.linspace(1, 21,10, endpoint = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM_7v2o4Wmah"
      },
      "source": [
        "#step 1: model training\n",
        "mu, sigma = estimateGaussian(train)\n",
        "\n",
        "#generate The probability density function/curve/surface/model for multivariate_normal given mean and cov \n",
        "model = multivariate_normal(mean=mu, cov=sigma, allow_singular = True)#surface hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ63Z1kt6Urs"
      },
      "source": [
        "\n",
        "pdfVal = model.pdf(valFeatures)\n",
        "print(max(pdfVal))#too small, can not differentiate\n",
        "print(min(pdfVal))\n",
        "\n",
        "p_val = model.logpdf(valFeatures)#Log of the pdf first, then apply to features, to change the magnitude of prob\n",
        "print(max(p_val))#\n",
        "print(min(p_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLUcuuoaADXA"
      },
      "source": [
        "p = model.logpdf(train)\n",
        "print(p.shape)\n",
        "print((p_val.shape))\n",
        "\n",
        "# print(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS1dGJNSX3ay"
      },
      "source": [
        "print(p_val)\n",
        "print(p_val < -500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CbvIg7ZC5SP"
      },
      "source": [
        "\n",
        "\n",
        "scores = []\n",
        "p_val = model.logpdf(valFeatures)#Log of the pdf\n",
        "\n",
        "# thresholds = np.linspace(-1000, -10,150)\n",
        "thresholds = np.linspace(min(p_val), max(p_val),200)#generate all candidate threshold, epsilon\n",
        "\n",
        "#step 2: CV to find optimal threshold: bestThreshold\n",
        "for threshold in thresholds:\n",
        "  y_pred = (p_val < threshold).astype(int)# list of 0 and 1\n",
        "  #calculate recall, precision and f1 for each (truth, pred) pair, corresponding to that threshold\n",
        "  scores.append([recall_score(valLabel, y_pred),\n",
        "                 precision_score(valLabel, y_pred),\n",
        "                 f1_score(valLabel, y_pred, average = \"binary\")])\n",
        "\n",
        "scores = np.array(scores)\n",
        "maxIndex = scores[...,2].ravel().argmax()#maxIndex of the column 2(f1_score) #193\n",
        "bestThreshold = thresholds[maxIndex]\n",
        "print(scores.shape)#each row is a pair of (recall, precision, f1) corresponding to a threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxGw0Xa7CQZw"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUv0mGzMYBf8"
      },
      "source": [
        "print(maxIndex)\n",
        "print(bestThreshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFGdBwq2_398"
      },
      "source": [
        "np.mean(train.iloc[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DKQiFDF__hk"
      },
      "source": [
        "mu[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1twCbnrmABGt"
      },
      "source": [
        "print(mu)\n",
        "# print(sigma)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsLzITjPAOde"
      },
      "source": [
        "#performance on test data\n",
        "#step 3: prediction on test data\n",
        "y_test_pred_raw = model.logpdf(testFeatures)\n",
        "y_pred_test = y_test_pred_raw < bestThreshold\n",
        "\n",
        "f1_score(testLabel, y_pred_test, average = \"binary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T-cwgMIJrxn"
      },
      "source": [
        "y_pred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikDtOJUuWrLU"
      },
      "source": [
        "#index of predicted outliers in test data\n",
        "predoutliersTest = np.asarray(np.where(y_pred_test))\n",
        "\n",
        "len(predoutliersTest[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jzeUbA9a3FU"
      },
      "source": [
        "predoutliersTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2AUkBtbAMEr"
      },
      "source": [
        "#outliers identified on test data feature column V1 V2\n",
        "plt.figure()\n",
        "plt.title(\"test_data with outlier flaged red\")\n",
        "plt.xlabel(\"V1\")\n",
        "plt.ylabel(\"V2\")\n",
        "plt.plot(testFeatures.iloc[:, 1],testFeatures.iloc[:,2],\"bx\")#plot v1 v2 as blue cross\n",
        "plt.plot(testFeatures.iloc[predoutliersTest[0],0],testFeatures.iloc[predoutliersTest[0],1],\"ro\")#re-plot the outliers as red dots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8qcwdvXEKQ"
      },
      "source": [
        "#outliers identified on test data feature column V2 V3\n",
        "plt.figure()\n",
        "plt.title(\"test_data with outlier flaged red\")\n",
        "plt.xlabel(\"V2\")\n",
        "plt.ylabel(\"V3\")\n",
        "plt.plot(testFeatures.iloc[:, 2],testFeatures.iloc[:,3],\"bx\")\n",
        "plt.plot(testFeatures.iloc[predoutliersTest[0],0],testFeatures.iloc[predoutliersTest[0],1],\"ro\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWb0ZCXEzoG"
      },
      "source": [
        "\n",
        "\n",
        "# generate evaluation metrics\n",
        "print(\"%s: %r\" % (\"accuracy_score is: \", accuracy_score(testLabel, y_pred_test)))\n",
        "print(\"%s: %r\" % (\"roc_auc_score is: \", roc_auc_score(testLabel, y_test_pred_raw)))\n",
        "print(\"%s: %r\" % (\"f1_score is: \", f1_score(testLabel, y_pred_test )))#string to int\n",
        "\n",
        "print (\"confusion_matrix is: \")\n",
        "cm = confusion_matrix(testLabel, y_pred_test)\n",
        "cmDF = pd.DataFrame(cm, columns=['pred_0', 'pred_1'], index=['true_0', 'true_1'])\n",
        "print(cmDF)\n",
        "print('recall =',float(cm[1,1])/(cm[1,0]+cm[1,1]))\n",
        "print('precision =', float(cm[1,1])/(cm[1,1] + cm[0,1]))#1.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XBjlsqlAQwP"
      },
      "source": [
        "#note we can apply supervised learning on this data too, but performance may be different, \n",
        "#can try use the output prob as an additional input feature of the supervised learning model, and see if it improved the model perf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlGZ1dSIAUaA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}